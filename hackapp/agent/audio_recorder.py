"""
Audio Recorder for Voice Workflows
Handles recording, transcription, and state management
"""

import threading
import time
from typing import Optional, Callable
import sys
import types

# Stub out modules for Python 3.13+ compatibility FIRST
for _mod_name in ("aifc", "audioop"):
    if _mod_name not in sys.modules:
        sys.modules[_mod_name] = types.ModuleType(_mod_name)

try:
    import numpy as np
    import sounddevice as sd
except (ImportError, OSError) as e:
    # OSError raised when PortAudio library not found
    # ImportError raised when packages not installed
    np = None
    sd = None
    if "PortAudio" not in str(e):
        print(f"âš ï¸  Audio libraries not available: {e}")

try:
    import speech_recognition as sr
except ImportError:
    sr = None

# Import recording indicator for visual feedback (after other imports)
try:
    from .recording_indicator import show_recording_indicator, hide_recording_indicator
    INDICATOR_AVAILABLE = True
except ImportError:
    try:
        # Fallback for direct execution
        from recording_indicator import show_recording_indicator, hide_recording_indicator
        INDICATOR_AVAILABLE = True
    except ImportError:
        INDICATOR_AVAILABLE = False
        # Silently fail - indicator is optional


class AudioRecorder:
    """Handles audio recording and transcription for voice workflows"""

    def __init__(self):
        self.is_recording = False
        self.audio_buffer = []
        self.stream = None
        self.recognizer = sr.Recognizer() if sr else None
        self.sample_rate = 16000
        self.transcription = None
        self.on_transcription_complete: Optional[Callable[[str], None]] = None

    def start_recording(self):
        """Start recording audio"""
        print("   ðŸ” [DEBUG] start_recording() called")

        if self.is_recording:
            print("   âš ï¸  Already recording")
            return False

        if not sd or not np:
            print("   âŒ sounddevice/numpy not installed")
            print(f"   ðŸ” [DEBUG] sd={sd}, np={np}")
            return False

        self.is_recording = True
        self.audio_buffer = []
        self.transcription = None

        print("   ðŸ”´ Recording started...")
        print(f"   ðŸ” [DEBUG] Sample rate: {self.sample_rate}")
        print(f"   ðŸ” [DEBUG] Buffer initialized: {len(self.audio_buffer)} chunks")

        # Show visual indicator
        if INDICATOR_AVAILABLE:
            try:
                show_recording_indicator()
                print("   âœ… [DEBUG] Visual indicator shown")
            except Exception as e:
                print(f"   âš ï¸  Could not show indicator: {e}")

        try:
            self.stream = sd.InputStream(
                samplerate=self.sample_rate,
                channels=1,
                dtype="int16",
                callback=self._audio_callback,
                blocksize=int(self.sample_rate * 0.1),  # 100ms blocks
            )
            self.stream.start()
            print("   âœ… [DEBUG] Audio stream started successfully")
            return True
        except Exception as e:
            print(f"   âŒ Failed to start recording: {e}")
            import traceback
            traceback.print_exc()
            self.is_recording = False
            # Hide indicator if start failed
            if INDICATOR_AVAILABLE:
                try:
                    hide_recording_indicator()
                except:
                    pass
            return False

    def stop_recording(self):
        """Stop recording and start transcription"""
        print("   ðŸ” [DEBUG] stop_recording() called")

        if not self.is_recording:
            print("   âš ï¸  Not currently recording")
            return False

        self.is_recording = False

        # Hide visual indicator
        if INDICATOR_AVAILABLE:
            try:
                hide_recording_indicator()
                print("   âœ… [DEBUG] Visual indicator hidden")
            except Exception as e:
                print(f"   âš ï¸  Could not hide indicator: {e}")

        if self.stream:
            self.stream.stop()
            self.stream.close()
            self.stream = None
            print("   âœ… [DEBUG] Audio stream stopped and closed")

        print(f"   ðŸ” [DEBUG] Captured {len(self.audio_buffer)} audio chunks")
        print("   â¹ï¸  Recording stopped")
        print("   ðŸ”„ Transcribing...")

        # Start transcription in background thread
        print("   ðŸ” [DEBUG] Starting transcription thread...")
        threading.Thread(target=self._transcribe, daemon=True).start()
        return True

    def _audio_callback(self, indata, frames, timeinfo, status):
        """Called by sounddevice on audio thread"""
        if self.is_recording:
            self.audio_buffer.append(indata.copy())
            # Print every 10 chunks to avoid spam
            if len(self.audio_buffer) % 10 == 0:
                print(f"   ðŸ” [DEBUG] Audio chunks captured: {len(self.audio_buffer)}")

    def _transcribe(self):
        """Transcribe recorded audio using Google Speech Recognition"""
        print("   ðŸ” [DEBUG] _transcribe() thread started")

        if not self.audio_buffer:
            print("   âš ï¸  No audio captured")
            print("   ðŸ” [DEBUG] audio_buffer is empty")
            return

        print(f"   ðŸ” [DEBUG] Processing {len(self.audio_buffer)} audio chunks")

        if not self.recognizer:
            print("   âŒ Speech recognizer not available (sr module not loaded)")
            return

        try:
            # Combine audio chunks
            print("   ðŸ” [DEBUG] Combining audio chunks...")
            combined = np.vstack(self.audio_buffer)
            print(f"   ðŸ” [DEBUG] Combined audio shape: {combined.shape}")

            audio_data = sr.AudioData(combined.tobytes(), self.sample_rate, 2)
            print(f"   ðŸ” [DEBUG] Created AudioData object, size: {len(combined.tobytes())} bytes")

            # Transcribe using Google
            print("   ðŸ” [DEBUG] Calling Google Speech Recognition API...")
            text = self.recognizer.recognize_google(audio_data, language="en-US")

            self.transcription = text
            print(f"   âœ… Transcribed: {text[:100]}...")
            print(f"   ðŸ” [DEBUG] Full transcription: {text}")

            # Call callback if registered
            if self.on_transcription_complete:
                print("   ðŸ” [DEBUG] Calling transcription callback...")
                self.on_transcription_complete(text)
                print("   âœ… [DEBUG] Callback completed")
            else:
                print("   âš ï¸  [DEBUG] No transcription callback registered")

        except sr.UnknownValueError:
            print("   âš ï¸  Could not understand audio")
            print("   ðŸ” [DEBUG] Speech Recognition could not parse the audio")
            self.transcription = None
        except sr.RequestError as e:
            print(f"   âš ï¸  API error: {e}")
            print(f"   ðŸ” [DEBUG] Request to Google API failed: {e}")
            self.transcription = None
        except Exception as e:
            print(f"   âŒ Transcription error: {e}")
            print("   ðŸ” [DEBUG] Traceback:")
            import traceback
            traceback.print_exc()
            self.transcription = None

        print("   ðŸ” [DEBUG] _transcribe() thread finished")

    def get_transcription(self) -> Optional[str]:
        """Get the transcription result"""
        return self.transcription

    def is_busy(self) -> bool:
        """Check if recording or transcribing"""
        return self.is_recording
